{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitch - Exploratory Data Analysis and Visualization\n",
    "\n",
    "*By- Shashank Shashikant Rao (ss5132) and Cyrus Dinyar Lala (cdl2141)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<p> \n",
       "\n",
       "To make sure our content, and analysis is not interrupted by large chunks of code, the Python/R scripts on this notebook are hidden \n",
       "by default. However, you can toggle this by clicking the button below.\n",
       "\n",
       "</p>\n",
       "\n",
       "\n",
       "<br/>\n",
       "\n",
       "\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle Show/Hide Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<p> \n",
    "\n",
    "To make sure our content, and analysis is not interrupted by large chunks of code, the Python/R scripts on this notebook are hidden \n",
    "by default. However, you can toggle this by clicking the button below.\n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle Show/Hide Code\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "div.text_cell_render { /* Customize text cells */\n",
       "font-family: 'Calibri';\n",
       "font-size:1.2em;\n",
       "line-height:1.4em;\n",
       "padding-left:3em;\n",
       "padding-right:3em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "\n",
    "div.text_cell_render { /* Customize text cells */\n",
    "font-family: 'Calibri';\n",
    "font-size:1.2em;\n",
    "line-height:1.4em;\n",
    "padding-left:3em;\n",
    "padding-right:3em;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><img src=\"report-assets/twitch-logo.png\"></p>\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "We have chosen to analyze viewership data from the game streaming website Twitch.tv. Below, we outline why we picked this topic, how we obtained the data and some general terminology associated with Twitch.\n",
    "\n",
    "\n",
    "### What is Twitch?\n",
    "\n",
    "Twitch is a live-streaming website which focuses mainly on gaming videos, live game playthroughs, eSport competition coverage. Viewers typically watch the content live, or via videos available on demand.\n",
    "\n",
    "Quoting wikipedia - *\"The site primarily focuses on video gaming, including playthroughs of video games, broadcasts of eSports competitions, creative content, and more recently, music broadcasts. Content on the site can either be viewed live or via video on demand. The popularity of Twitch would eclipse that of its general-interest counterpart; in October 2013, the website had 45 million unique viewers, and by February 2014, it was considered the fourth largest source of peak Internet traffic in the United States.\" *\n",
    "\n",
    "Read more about twitch on their official website <a href=\"https://www.twitch.tv/p/about\">here</a>.\n",
    "\n",
    "### Why Analyze Twitch Data?\n",
    "\n",
    "We chose this topic because of our interest in gaming, as well as the fact that we wanted the experience of using a REST API to periodically pull data and generate our own data store using Amazon web services. Amazon bought Twitch for ~1 billion dollars, and we were very curious about some specific aspects of Twitch that we discuss below. We were also interested in analysing user behavior online and finding out how that changes over time. Another cool aspect of this analysis is that, all the data is collected LIVE as the games/gaming tournaments take place.\n",
    "\n",
    "### General Terminology/Vocabulary\n",
    "\n",
    "The gamers who broadcast live on twitch or share content have \"**channels**\". The videos/live **streams** are available on their channels. Channels could belong to individuals or eSports companies who could stream gaming competitions.\n",
    "\n",
    "**Viewers** typically subscribe to/follow specific channels to receive notifications about when the channel is 'live' or streaming content.\n",
    "\n",
    "There is a variety of content streamed on Twitch. Apart from gaming videos, the site also features Talk Shows, IRL (In Real Life) video blogs ('vlogs') etc. Some of the absurd (but great!) content we found on Twitch was a continuous loop of the popular TV show 'Power Rangers' and even some streams tagged 'Casino' which feature players playing different games such as Poker.\n",
    "\n",
    "\n",
    "### Questions we are looking to answer:\n",
    "\n",
    "* What are the most popular games on twitch during a given time period?\n",
    "\n",
    "\n",
    "* What are the most popular channels?\n",
    "\n",
    "\n",
    "* What genre of game gets the most viewers?\n",
    "\n",
    "\n",
    "* How does viewership vary with time of day or external events like tournaments?\n",
    "\n",
    "\n",
    "* How does a streamers quality (frame rate, video quality) affect viewership?\n",
    "\n",
    "\n",
    "* What kind of games are trending upwards in popularity during a given time period?\n",
    "\n",
    "\n",
    "* How does stream viewership vary by time/geography?\n",
    "\n",
    "\n",
    "### Data Source\n",
    "\n",
    "The data for this project was obtained by using the REST API provided by Twitch. They provide clear instructions on how to structure GET requests and they return the data in JSON format. Since the project required analysis of \"LIVE\" twitch data, we wrote a Python script to fetch required data. We then pushed this script onto an Amazon AWS EC2 instance. The script was executed every 10 minutes using a cron job. After data cleaning, the data was then stored in a MySQL database hosted on Amazon RDS (part of AWS). To perform the analysis, time series data for various streams/games/channels was fetched locally from the MySQL instance. \n",
    "\n",
    "We also performed ‘one time’ pulls/fetches to obtain game-specific information such as 'genre' from a game review site called giantbomb. \n",
    "\n",
    "The giantbomb API documentation can be found here: https://www.giantbomb.com/api/documentation\n",
    "\n",
    "The documentation for the twitch API can be found here: https://dev.twitch.tv/docs\n",
    "\n",
    "* Data Fetch/Cleanup code is located here: \n",
    "    - https://github.com/shashankrao/TwitchDataAnalysis/blob/master/notebooks-code/Giantbomb_Pull.ipynb\n",
    "    - https://github.com/shashankrao/TwitchDataAnalysis/blob/master/notebooks-code/Giantbomb_Cleanup.ipynb\n",
    "    - https://github.com/shashankrao/TwitchDataAnalysis/blob/master/notebooks-code/TwitchScraper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Team \n",
    "\n",
    "*Team Members: Shashank Shashikant Rao (ss5132) and Cyrus Dinyar Lala (cdl2141)*\n",
    "\n",
    "This section outlines the split up of tasks for the different stages of the project. We tried to evenly distribute work between us or work on things together.\n",
    "\n",
    "**Data Scraping and Cleaning & Initial work**:\n",
    "\n",
    "We set up the ‘live’ part of our data collection by working together. At the same time we worked together on ideating questions, and wrangling the data. After initial discussion on the important questions we wanted to ask, we spent some time understanding what kind of data is required and what visualizations would be best suited for each.\n",
    "\n",
    "**Split up of analysis work completed:**\n",
    "\n",
    "*Cyrus*: \n",
    "\n",
    "- Analysed the Twitch API, and worked on formulating the REST queries. \n",
    "\n",
    "\n",
    "- Worked on getting the SQL setup properly (schema etc). Set up the SQL Query script/workflow to aggregate and fetch data.\n",
    "\n",
    "\n",
    "- Worked on analyzing games that have upward trends.\n",
    "\n",
    "\n",
    "- Exploratory data analysis in R.\n",
    "\n",
    "\n",
    "- Analysing how fps and video height vary with channels.\n",
    "\n",
    "\n",
    "- Generated heatmaps to show game stream viewership by day-of-week/hour-of-day. (in R) \n",
    "\n",
    "\n",
    "\n",
    "*Shashank:* \n",
    "\n",
    "- Worked on setting up instances on AWS (setup API key with Twitch) \n",
    "\n",
    "\n",
    "- Wrote python code to get/fetch the data. Did some data cleaning in Pandas (Python) and pushed data into SQL\n",
    "\n",
    "\n",
    "- Worked on fetching game related data from Giantbomb. \n",
    "\n",
    "\n",
    "- Initial exploratory analysis of the game based genres.\n",
    "\n",
    "\n",
    "- Setup the initial notebook with interoperability between R and Python.\n",
    "\n",
    "\n",
    "- Generated Time-Series visualization in D3 along with Daylight-map.\n",
    "\n",
    "\n",
    "\n",
    "*Worked together on:*\n",
    "\n",
    "- Visualizing ranking of games.\n",
    "\n",
    "\n",
    "- Looking at anomalies in 'Street Fighter V' viewership.\n",
    "\n",
    "\n",
    "- Looking at 'GTA V' viewership.\n",
    "\n",
    "\n",
    "- Analysing trends of how streamers reach 'peak' viewership.\n",
    "\n",
    "\n",
    "- General Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis of Data Quality\n",
    "\n",
    "Going by the definition of data quality, the section below looks at how well the data correctly represents the real-world construct i.e Twitch viewers and streamers. The data is directly fetched using Twitch’s REST API. To obtain the data we used a Twitch Identity created for this project (or 'api-key'). \n",
    "\n",
    "Our data comes in the form of 3 main tables. Each is indexed by timestamp at which the row was requested. One provides summary data for twitch as a whole, one provides data summarized by game for a set list of games that we created, and the third provides data on the top 100 active channels per game in our list at that timestamp.\n",
    "\n",
    "Given the fact that we had to obtain the data from an external source which ‘produces’ data points at every instant, we have outlined the different aspects of data quality below.\n",
    "\n",
    " - **Inconsistency**\n",
    "\n",
    "There might be some inconsistency in between the different types of data we have fetched from twitch. This might come from the fact that the data is obtained from different REST queries. We make efforts to handle the slight inconsistencies between tables, and also use aggregation to alleviate these issues. \n",
    "\n",
    "\n",
    "\n",
    "- **Incompleteness**\n",
    "\n",
    "From the perspective of our analysis and visualizations, the data is not incomplete. It provides all the attributes we require, at 10 minute intervals.\n",
    "\n",
    "\n",
    "- **Accuracy**\n",
    "\n",
    "The accuracy of our data depends on the data provided by Twitch. Most probably, Twitch is doing some approximation/aggregation while providing viewer numbers and other stream related data such as FPS. \n",
    "\n",
    "\n",
    "- **Latency**\n",
    "\n",
    "The data is fetched every 10 minutes. The entire data fetch is executed in sequence:\n",
    "    * Fetch the top 100 games being streamed\n",
    "    * Fetch the information about the top 100 streamers for a pre-defined set of games\n",
    "    * Fetch overall summary.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **Precision**\n",
    "\n",
    "The data is precise to every 10 minutes. There may be variation in between 10 minute intervals that is not accounted for caused by delays in API requests or approximation from Twitch's end. Additionally, we use aggregation to get the amount of viewers per stream per hour, day etc. (we do not have unique viewer information available to us, only counts per channel or game at snapshots in time). Therefore, while this is not strictly accurate, it gives a good estimate of the amount of unique viewers per hour/day given the data available.\n",
    "\n",
    "\n",
    "\n",
    "- **Missing / Unknown**\n",
    "\n",
    "The data does have some missing or unknown values. But the attributes that are unknown are low priority/impact. Example fields missing: \"is_playlist\";\"ch_broadcaster_language\". We reduced missing values at the time of data collection, and only selected values relevant to our analysis from the REST API response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries and set plot parameters\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'png')\n",
    "plt.rcParams['savefig.dpi'] = 75\n",
    "\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scipy as scipy\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.dates as mdates\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sole_value = lambda x : list(x)[0]\n",
    "\n",
    "\n",
    "# %load_ext rpy2.ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'dfWithGenre.csv' does not exist: b'dfWithGenre.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e1a5cbfea5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgiantbombdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfWithGenre.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'dfWithGenre.csv' does not exist: b'dfWithGenre.csv'"
     ]
    }
   ],
   "source": [
    "giantbombdf = pd.read_csv('dfWithGenre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'twitch_games.csv' does not exist: b'twitch_games.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2b0dd7411d40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'twitch_games.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'twitch_games.csv' does not exist: b'twitch_games.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('twitch_games.csv')\n",
    "df['time'] =pd.to_datetime(df['timestamp'],unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Storage:\n",
    "\n",
    "* **Table 1: twitch_games**  - data aggregated by game per 10 mins\n",
    "\n",
    "\n",
    "* **Table 2: twitch_streams** - data on top 100 streams per game per 10 mins\n",
    "\n",
    "\n",
    "* **Table 3: twitch_summary** - data aggregated for all of twitch per 10 mins\n",
    "\n",
    "Below we show the top few rows, summary statistics and rough looks at distributions of the variables in these tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'twitch_games'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBig = pd.read_csv('twitch_streams.csv', sep=\";\")\n",
    "#add formatted time to data frame\n",
    "dfBig['time'] =pd.to_datetime(dfBig['timestamp'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'twitch_streams'\n",
    "dfBig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary = pd.read_csv('twitch_summary.csv', sep =';')\n",
    "dfSummary['time'] =pd.to_datetime(dfSummary['timestamp'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'twitch_summary'\n",
    "dfSummary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary Statistics and Distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'twitch_games'\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'twitch_games'\n",
    "\n",
    "df.hist(figsize=(25,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'twitch_streams'\n",
    "dfBig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'twitch_streams'\n",
    "dfBig.hist(figsize=(25,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'twitch_summary'\n",
    "dfSummary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'twitch_summary'\n",
    "\n",
    "dfSummary.hist(figsize=(20,8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Executive Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to analyze data from the streaming website Twitch.tv. The data on hand was viewership data for different channels and gaming live-streams, collected every 10 minutes.\n",
    "\n",
    "We looked at how viewership varies during the time for which the data was collected. We saw that the viewer numbers for a particular game were affected by a few 'key' external factors outside of just general popularity of the game. We will list those and show supporting data for them below.\n",
    "\n",
    "- Impact of e-sports events (tournaments) on game viewership\n",
    "- The impact of big streamers' followers on game viewership\n",
    "- The impact of time/geography on game viewership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Impact of e-sports events (tournaments) on game viewership\n",
    "\n",
    "Below is a plot of viewers over time for the game Street Fighter V. If you look at the general pattern for Street Fighter V viewers, the number usually hovers somewhere around ~2,500 at any given point in time. However, we noticed that there were sometimes massive spikes that went up to 30,000-40,000 viewers (more than 10x increase!). Upon investigation we found that these spikes were related to tournaments and competitive events. In the below chart, you can see an example of this through the massive effect of The ELEAGUE Street Fighter V Invitational (link below) on street fighter viewership during this time period. We saw a similar effect of large tournaments in other games as well.\n",
    "\n",
    "\n",
    "Tournament link: http://www.eleague.com/street-fighter-v/bracket#QG67Nc4Jhiqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impact of tournaments on Street Fighter Viewership, ELeague example\n",
    "sfDF = dfBig.loc[dfBig['stream_game']==\"Street Fighter V\"]\n",
    "#sfDF = sfDF.loc[sfDF['timestamp']< 1491436800]\n",
    "topSF = sfDF.loc[sfDF[\"rank\"]==1]\n",
    "\n",
    "eLeagueSF = sfDF.loc[sfDF[\"ch_channel_name\"]==\"eleaguetv\"]\n",
    "eLeagueSF = eLeagueSF.set_index(\"time\")\n",
    "eLeagueSF = eLeagueSF.resample(\"10 min\")\n",
    "eLeagueSF= eLeagueSF.mean()\n",
    "eLeagueSF['viewers'] = eLeagueSF['viewers'].fillna(0)\n",
    "\n",
    "\n",
    "thisDF = df.loc[df['name'] == \"Street Fighter V\"]\n",
    "#thisDF = thisDF.loc[thisDF['timestamp']< 1491436800]\n",
    "anotherDF =thisDF.iloc[:1600]\n",
    "\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "\n",
    "plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = \"All SF Viewers\")\n",
    "#plt.plot(topSF['time'],topSF['viewers'].values, label = \"Top SF Streamer Viewers\")\n",
    "plt.plot(list(eLeagueSF.index),list(eLeagueSF['viewers'].values), label = \"E league Viewers\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"Impact of E league Event on Street Fighter V Viewership\")\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The impact of big streamers' followers on game viewership\n",
    "\n",
    "Below we have a chart that shows us the following two things:\n",
    "1. During this time period, there was an upward trend in the average number of people watching a Grand Theft Auto V (GTA V) stream at any given point in time. Notice that similar to the Street Fighter V data before, there are sudden large spikes in viewership.\n",
    "2. We then draw dotted vertical lines for when the three popular streamers 'summit1g', 'lirik' and 'giantwaffle' reach a local peak in their viewership over time (i.e. they start streaming and pick up viewers), and we can see that the spikes in viewership correspond almost exactly to the time that these streamers begin broadcasting.\n",
    "\n",
    "These three streamers possess some of the largest individual (non-organization) channels on twitch and have massive follower bases. They generally stream other games besides GTA V, but the below chart shows that their fan base will follow them from game to game, implying that they are more interested in watching the streamer personality than the particular game that they might be playing. \n",
    "\n",
    "As such, if a game was to invite a large streamer to come and beta test or play a particular game, that could be a very good advertising strategy to give the game some exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which games rise over time - GTA V\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "thisDF = df.loc[df['name'] == \"Grand Theft Auto V\"]\n",
    "#thisDF = thisDF.loc[thisDF['timestamp']< 1491436800]\n",
    "anotherDF =thisDF\n",
    "\n",
    "x=np.arange(len(anotherDF['viewers'].values))\n",
    "fit = np.polyfit(x ,anotherDF['viewers'].values, deg = 1)\n",
    "\n",
    "plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = \"Grand Theft Auto V\")\n",
    "plt.plot(anotherDF['time'], fit[0]*x +fit[1], color = 'red', label='Linear Trend')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"GTA V - Viewers over Time\")\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "thisDF = df.loc[df['name'] == \"Grand Theft Auto V\"]\n",
    "#thisDF = thisDF.loc[thisDF['timestamp']< 1491436800]\n",
    "anotherDF =thisDF\n",
    "\n",
    "summitDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"summit1g\"]\n",
    "summitDF = summitDF.loc[summitDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "lirikDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"lirik\"]\n",
    "lirikDF = lirikDF.loc[lirikDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "giantwaffleDF=dfBig.loc[dfBig[\"ch_channel_name\"]==\"giantwaffle\"]\n",
    "giantwaffleDF = giantwaffleDF.loc[giantwaffleDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "\n",
    "plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = \"Grand Theft Auto V Viewers\")\n",
    "#plt.plot(summitDF['time'],anotherDF['viewers'].values, label = \"Summit Playing GTA\")\n",
    "#plt.plot(lirikDF['time'],lirikDF['viewers'].values, label = \"Lirik Playing GTA\")\n",
    "\n",
    "prev = None\n",
    "for t in lirikDF['time']:\n",
    "    if prev != None:\n",
    "        if (t-prev) > pd.tslib.Timedelta(minutes=240):\n",
    "            plt.axvline(t, color='green', linestyle='--', alpha=0.5, label = \"Lirik Stream\" )\n",
    "    prev = t\n",
    "prev = None\n",
    "for t in summitDF['time']:\n",
    "    if prev != None:\n",
    "        if (t-prev) > pd.tslib.Timedelta(minutes=240):\n",
    "            plt.axvline(t, color='red', linestyle='--', alpha=0.5, label = \"Summit Stream\" )\n",
    "    prev = t\n",
    "prev = None\n",
    "for t in giantwaffleDF['time']:\n",
    "    if prev != None:\n",
    "        if (t-prev) > pd.tslib.Timedelta(minutes=240):\n",
    "            plt.axvline(t, color='black', linestyle='--', alpha=0.5, label = \"Giantwaffle Stream\" )\n",
    "    prev = t\n",
    "    \n",
    "    \n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = OrderedDict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(),bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\"Timing of Big Streamers with GTA V Viewer Spikes\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The impact of time/geography on game viewership\n",
    "\n",
    "We also analyzed the impact of time of day on viewership for a particular game.\n",
    "In the below heatmap, we look at average viewership numbers during each hour of the week.\n",
    "(Our data is in the UTC timezone) Notice that the brighter (higher) values are concentrated around hours 15-23. This roughly corresponds to afternoon-night in the USA and the evening-late night in Europe. If you assume that a lot of gaming occurs in the evening when people get back home from school or work, this could imply that viewership is concentrated in the USA and Europe, however it is hard to pin-point exactly what is going on from just the heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#are there games that peak at different time periods?\n",
    "heatMapGameList = [\"PLAYERUNKNOWN'S BATTLEGROUNDS\"]\n",
    "\n",
    "thisDF = df.loc[df['name'].isin(heatMapGameList)]\n",
    "#aggregate data by hour of day/day of week\n",
    "thisDF[\"Hour\"] = thisDF[\"time\"].dt.hour\n",
    "thisDF[\"DOW\"] = thisDF[\"time\"].dt.dayofweek\n",
    "\n",
    "f = {'viewers':['mean'], 'name':sole_value, 'DOW': sole_value, 'Hour': sole_value}\n",
    "\n",
    "thisSubGroup= thisDF.groupby(['DOW', 'Hour','name']).agg(f)\n",
    "thisDF = pd.DataFrame(thisSubGroup)\n",
    "thisDF.columns = [\"hour\", \"name\", \"viewersMean\", \"dow\"]\n",
    "neededdf = thisDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i neededdf -w 800 -h 500\n",
    "\n",
    "library(ggplot2)\n",
    "library(viridis)\n",
    "neededdf <- as.data.frame(neededdf)\n",
    "\n",
    "\n",
    "#divide by max scaler\n",
    "#neededdf$viewers= neededdf$viewers/max(neededdf$viewers)\n",
    "ggplot(data = neededdf, aes(x = dow, y = hour)) +\n",
    "  geom_tile(aes(fill = viewersMean/1000)) + \n",
    "  scale_fill_viridis(name = \"Thousands of Viewers (Mean)\") +\n",
    " labs(title=\"PUBG Viewer HeatMap\", x= \"Day Of Week (Monday-0 to Sunday-6)\", y = \"Hour Of Day 0-24\") +\n",
    "  theme(plot.title = element_text(hjust = 0.5))+ \n",
    " facet_wrap(~name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have an **interactive** (you can hover your mouse over the time-series line chart) visualization that tells a better story.\n",
    "\n",
    "We look at the game FIFA 2017, a soccer game, and observe that the peaks occur in the early evening-night in Europe, where soccer is extremely popular. From this and our evening gaming assumption, we can infer that the viewership for FIFA is mostly concentrated in Europe. \n",
    "\n",
    "(Direct link to visualization: https://cyruslala.github.io/EDAV_Columbia2017_Twitch/d3/fifaindex.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<style>\n",
    "    #frame { width: 1000px; height:800px; border: 1px solid black; }\n",
    "    #frame {\n",
    "        -ms-zoom: 0.95;\n",
    "        -moz-transform: scale(0.95);\n",
    "        -moz-transform-origin: 0 0;\n",
    "        -o-transform: scale(0.95);\n",
    "        -o-transform-origin: 0 0;\n",
    "        -webkit-transform: scale(0.95);\n",
    "        -webkit-transform-origin: 0 0;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div id=\"wrap\">\n",
    "<iframe id=\"frame\" src=\"https://cyruslala.github.io/EDAV_Columbia2017_Twitch/d3/fifaindex.html\"></iframe>\n",
    "</div>\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even more interesting story can be seen in the data for *'Dota 2'*, a very popular MOBA(Multiplayer Online Battle Arena) game that is played accross the world.\n",
    "\n",
    "The two things of interest to note here are:\n",
    "\n",
    "1. Around the start of April, we see large spikes in viewership, during the daytime in China. This is due to the Dota Asia Championships 2017 that were held in China during those dates. People around the world were tuning in as the tournament took place in China. You can read more about the tournament <a href=\"http://www.dota2.com.cn/dac/english/match?date=04-01\">here.</a>\n",
    "\n",
    "2. Apart from some outliers, we noticed that there are multiple peaks in viewership per-day for Dota. These seem to occur during night time in US and Europe. This can be observed as a plateau of peak viewership as night progresses in Europe and Asia, since players and streamers come in and out at their respective evening and night times.\n",
    "\n",
    "(Direct link to visualization: https://cyruslala.github.io/EDAV_Columbia2017_Twitch/d3/dotaindex.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "HTML('''<style>\n",
    "    #frame { width: 1000px; height:800px; border: 1px solid black; }\n",
    "    #frame {\n",
    "        -ms-zoom: 0.95;\n",
    "        -moz-transform: scale(0.95);\n",
    "        -moz-transform-origin: 0 0;\n",
    "        -o-transform: scale(0.95);\n",
    "        -o-transform-origin: 0 0;\n",
    "        -webkit-transform: scale(0.95);\n",
    "        -webkit-transform-origin: 0 0;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div id=\"wrap\">\n",
    "<iframe id=\"frame\" src=\"https://cyruslala.github.io/EDAV_Columbia2017_Twitch/d3/dotaindex.html\"></iframe>\n",
    "</div>\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching and Cleaning Data\n",
    "\n",
    "* Data Fetch/Cleanup code is located here: \n",
    "    - https://github.com/shashankrao/TwitchDataAnalysis/blob/master/notebooks-code/Giantbomb_Pull.ipynb\n",
    "    - https://github.com/shashankrao/TwitchDataAnalysis/blob/master/notebooks-code/Giantbomb_Cleanup.ipynb\n",
    "    - https://github.com/shashankrao/TwitchDataAnalysis/blob/master/notebooks-code/TwitchScraper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Analysis (Data Exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by looking at ‘big’ streams that had 5000+ viewers at some point. This gives us some idea about viewer numbers on Twitch. \n",
    "\n",
    "Note: Most of the twitch data is \"top-heavy\" in viewers and \"bottom-heavy\" in channels/streams, meaning that the vast majority of the viewership happens in the top few channels, and the vast majority of channels have very few concurrent viewers, so for many of our charts we consider high ranking or top games and streams to avoid a lot of data centered at 0. This pattern is evident even in the plots below that are filtered for 'big' streams and channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr1 = dfBig[dfBig[\"viewers\"] > 5000][[\"viewers\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i dfr1 -w 800 -h 500\n",
    "library(plyr)\n",
    "library(ggplot2)\n",
    "\n",
    "#Most are centered around 0, so we can look at only 'big' streams that had 1000+ viewers at some point\n",
    "ggplot(dfr1, aes(x = viewers/1000)) + \n",
    "  geom_histogram(binwidth = .5) +\n",
    "    xlab(\"Thousands of Viewers\") +\n",
    "  ggtitle(\"Viewers/Stream at a point in time Histogram (Streams/times with atleast 5000 viewers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also lookup a streams ‘rank’. We define rank of a stream as its position within a game’s top streams. Eg: Rank 1 for Dota 2 means at a particular timestamp, that stream was the most watched stream for Dota 2. Below, we look at viewers of streams that had a rank of 7 or above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr2 = dfBig[dfBig[\"rank\"] < 8][[\"viewers\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i dfr2 -w 800 -h 500\n",
    "\n",
    "ggplot(dfr2, aes(x = viewers/1000)) + \n",
    "    xlab(\"Thousands of Viewers\") +\n",
    "  geom_histogram(binwidth = .5) +\n",
    "  ggtitle(\"Viewers/Stream at a point in time Histogram (High Ranking Streams)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider high ranking channels and observe the histogram of how many followers a channel has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr3 = dfBig[dfBig[\"rank\"] < 10][[\"ch_followers\", \"ch_channel_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i dfr3 -w 800 -h 500\n",
    "\n",
    "#look at a follower histogram\n",
    "#Select Max followers per channel (i.e. latest data)\n",
    "maxFollowers = ddply(dfr3 , .(ch_channel_name), summarize, latestfollowers = max(ch_followers))\n",
    "ggplot(maxFollowers[which(maxFollowers$latestfollowers>5000),], aes(x = latestfollowers/1000)) + \n",
    "    xlab(\"Thousands of Followers\") +\n",
    "  geom_histogram(binwidth = 10) +\n",
    "  ggtitle(\"Followers per Channel Histogram (Channels with over 5000 followers)\")  + guides(fill = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is in time-series form and the vast majority of the analysis is done over time. Before we get into that, we performed some aggregation to answer some basic questions such as which games/channels/genres are the most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the most popular games (Aggregated)\n",
    "thisDF = df\n",
    "#aggregate data by hour of day/day of week\n",
    "thisDF[\"Hour\"] = thisDF[\"time\"].dt.hour\n",
    "thisDF[\"DOW\"] = thisDF[\"time\"].dt.dayofweek\n",
    "\n",
    "#note: using max viewers during this time period\n",
    "f = {'viewers':['max'], 'name':sole_value}\n",
    "thisSubGroup= thisDF.groupby(['name']).agg(f)\n",
    "thisDF = pd.DataFrame(thisSubGroup)\n",
    "\n",
    "thisDF.columns = ['game', 'viewers']\n",
    "thisDF = thisDF.sort(['viewers'], ascending=0)\n",
    "\n",
    "ax = thisDF[\"viewers\"][0:20].plot(kind='barh', subplots=True, figsize=(15,8), color=\"purple\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Maximum Viewers\")\n",
    "plt.ylabel(\"Game\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the most popular channels? - followers\n",
    "thisDF = dfBig\n",
    "#aggregate data by hour of day/day of week\n",
    "thisDF[\"Hour\"] = thisDF[\"time\"].dt.hour\n",
    "thisDF[\"DOW\"] = thisDF[\"time\"].dt.dayofweek\n",
    "\n",
    "f = {'ch_followers':['max'], 'ch_views':['max'], 'ch_channel_name':sole_value}\n",
    "thisSubGroup= thisDF.groupby(['ch_channel_name']).agg(f)\n",
    "thisDF = pd.DataFrame(thisSubGroup)\n",
    "\n",
    "\n",
    "thisDF.columns = ['name', 'followers', 'views']\n",
    "\n",
    "thisDF = thisDF.sort(['followers'], ascending=0)\n",
    "\n",
    "ax = thisDF[\"followers\"][0:20].plot(kind='barh', subplots=True, figsize=(15,8), color=\"purple\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Followers\")\n",
    "plt.ylabel(\"Channel\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the most popular channels? - views\n",
    "thisDF =thisDF.sort(['views'], ascending=0)\n",
    "\n",
    "ax = thisDF[\"views\"][0:20].plot(kind='barh', subplots=True, figsize=(15,8), color=\"purple\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Total Views\")\n",
    "plt.ylabel(\"Channel\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we analyzed the average viewers per genre of the game (at any snapshot in time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewGenre = giantbombdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreList = dfNewGenre.groupby(by='genre')['viewers'].max()\n",
    "genreList =genreList[(genreList > 40000)]\n",
    "genreList=list(genreList.index)\n",
    "genreList.remove('unknown')\n",
    "random.shuffle(genreList)\n",
    "#print genreList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaxisvals = []\n",
    "for i in range(0,len(genreList)):\n",
    "    #thisDF = dfWithGenre.loc[dfWithGenre['gbGenre'] == genreList[i]]\n",
    "    secondary = dfNewGenre.loc[dfNewGenre['genre'] == genreList[i]]\n",
    "    f = {'viewers':['sum'], 'time':sole_value}\n",
    "    anothersecDF = secondary.groupby(by=[\"genre\", \"timestamp\"])[\"time\", \"viewers\"].agg(f)\n",
    "    finalDF = pd.DataFrame(anothersecDF)\n",
    "    vals = finalDF['viewers'].values\n",
    "    totalvals = vals.sum()\n",
    "    meanvals = totalvals/ (1.0*len(finalDF['time']))\n",
    "    yaxisvals.append(meanvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreBarDF = pd.DataFrame(columns= ['genre','Average Viewers'])\n",
    "genreBarDF['genre'] = genreList\n",
    "genreBarDF['Average Viewers'] = yaxisvals\n",
    "genreBarDF.index = genreBarDF['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreBarDF =genreBarDF.sort(['Average Viewers'], ascending=0)\n",
    "\n",
    "ax = genreBarDF[\"Average Viewers\"][0:20].plot(kind='barh', subplots=True, figsize=(10,8), color=\"purple\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Average Viewers\")\n",
    "plt.ylabel(\"Genre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot overall twitch viewership (every 10 minutes) over the time period in our data. We observe a cyclical pattern in viewership over time, and we also observe the presence of multiple peaks in some of the cycles. We will analyze and discuss this later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr4 = dfSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i dfr4 -w 800 -h 500\n",
    "ggplot(dfr4, aes(x=time, y =viewers)) + \n",
    "  geom_bar(stat='identity') + ggtitle(\"Twitch Viewers over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now slice our data by game, and look at viewership over a 48 hour period for games that have crossed the threshold of 50k viewers at some point in our data. \n",
    "\n",
    "We observe that the top 5-6 games are fairly consistently much higher than any of the other games.\n",
    "\n",
    "We then look at the same plot with rank instead of viewers. Once again, we observe that the top 5-6 games form a band at the top while the others vary greatly. The third plot shows just the top 5 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1 - Game Popularity - Viewers\n",
    "\n",
    "gameList = df.groupby(by='name')['viewers'].max()\n",
    "gameList =gameList[(gameList > 50000)]\n",
    "gameList=list(gameList.index)\n",
    "\n",
    "#print len(gameList)\n",
    "#print gameList\n",
    "gameList.remove('Tower Unite')\n",
    "thisDF = df.loc[df['name'].isin(gameList)]\n",
    "random.shuffle(gameList)\n",
    "#print gameList\n",
    "\n",
    "\n",
    "plt.figure(figsize = (15,7))\n",
    "\n",
    "for i in range(0, len(gameList)):\n",
    "    thisDF = df.loc[df['name'] == gameList[i]]\n",
    "    anotherDF =thisDF.iloc[::6,:].iloc[:50]\n",
    "    plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = gameList[i], color= plt.get_cmap('Vega20')(i))\n",
    "myFmt = mdates.DateFormatter('%m-%d %H:00')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"Viewers Over Time by Game\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1 - Game Popularity - Rank\n",
    "plt.figure(figsize = (15,7))\n",
    "\n",
    "for i in range(0, len(gameList)):\n",
    "    thisDF = df.loc[df['name'] == gameList[i]]\n",
    "    anotherDF =thisDF.iloc[::6,:].iloc[:50]\n",
    "    plt.plot(anotherDF['time'],anotherDF['rank'].values, label = gameList[i], color= plt.get_cmap('Vega20')(i))\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "myFmt = mdates.DateFormatter('%m-%d %H:00')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\"Rank Over Time by Game\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Rank\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topGameList = df.groupby(by='name')['viewers'].max()\n",
    "\n",
    "topGameList =topGameList[(topGameList > 130000)]\n",
    "topGameList=list(topGameList.index)\n",
    "\n",
    "\n",
    "#Question 1 - Game Popularity - Rank\n",
    "plt.figure(figsize = (15,7))\n",
    "\n",
    "for i in range(0, len(topGameList)):\n",
    "    thisDF = df.loc[df['name'] == topGameList[i]]\n",
    "    anotherDF =thisDF.iloc[::6,:].iloc[:50]\n",
    "    plt.plot(anotherDF['time'],anotherDF['rank'].values, label = topGameList[i], color= plt.get_cmap('Set1')(i))\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "myFmt = mdates.DateFormatter('%m-%d %H:00')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\"Rank Over Time by Game - Top 5 Games\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Rank\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the wide variations in rank for 'Street Fighter V'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"report-assets/SF5.png\" width=\"300px;\" height=\"200px\" />\n",
    "\n",
    "We found it interesting that there were some games that varied so widely in rank, so we decided to look at the data for 'Street Fighter V' and dig deeper.\n",
    "\n",
    "As expected, we saw a pattern with multiple spikes that went drastically over the regular pattern (~3000 to ~35000). \n",
    "We then tried to track down the channels that were active during the spike periods and had large viewer numbers. We found that the channel 'eleaguetv' (https://www.twitch.tv/eleaguetv) was active during the first few spikes. After some research we found that this channel was an organization holding a tournament* and streaming it, and this is what was causing the spike in viewership. \n",
    "To further illustrate this effect, we plotted the viewer numbers for eleaguetv alongside the numbers for Street Fighter V in total on the same graph for the relevant time period.\n",
    "\n",
    "This is one example of the massive effect a competitive event can have on viewership for a particular game.\n",
    "\n",
    "*-(The ELEAGUE Street Fighter V Invitational - http://www.eleague.com/street-fighter-v/bracket#QG67Nc4Jhiqx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Street Fighter Global Viewers - notice erratic spike pattern\n",
    "thisDF = df.loc[df['name'] == \"Street Fighter V\"]\n",
    "anotherDF =thisDF\n",
    "\n",
    "plt.figure(figsize = (15,7))\n",
    "plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = \"Street Fighter V\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"Street Fighter V - Viewers Over Time\")\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impact of tournaments on Street Fighter Viewership, ELeague example\n",
    "sfDF = dfBig.loc[dfBig['stream_game']==\"Street Fighter V\"]\n",
    "#sfDF = sfDF.loc[sfDF['timestamp']< 1491436800]\n",
    "topSF = sfDF.loc[sfDF[\"rank\"]==1]\n",
    "\n",
    "eLeagueSF = sfDF.loc[sfDF[\"ch_channel_name\"]==\"eleaguetv\"]\n",
    "eLeagueSF = eLeagueSF.set_index(\"time\")\n",
    "eLeagueSF = eLeagueSF.resample(\"10 min\")\n",
    "eLeagueSF= eLeagueSF.mean()\n",
    "eLeagueSF['viewers'] = eLeagueSF['viewers'].fillna(0)\n",
    "\n",
    "\n",
    "thisDF = df.loc[df['name'] == \"Street Fighter V\"]\n",
    "#thisDF = thisDF.loc[thisDF['timestamp']< 1491436800]\n",
    "anotherDF =thisDF.iloc[:1600]\n",
    "\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "\n",
    "plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = \"All SF Viewers\")\n",
    "#plt.plot(topSF['time'],topSF['viewers'].values, label = \"Top SF Streamer Viewers\")\n",
    "plt.plot(list(eLeagueSF.index),list(eLeagueSF['viewers'].values), label = \"E league Viewers\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"Impact of E league Event on Street Fighter V Viewership\")\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which games are tending updwards/downwards in viewership?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we decided to search for examples of games that were trending upwards or downwards in viewership during the time period of our data.\n",
    "\n",
    "An example of a downward trend was seen with the game 'The Legend of Zelda: Breath of the Wild'. This game was recently released (March 3, 2017) and was highly anticipated and recieved rave reviews and ratings. Our hypothesis is that given the single-player nature of the game and the fact that it is made for console, many people have already completed it or watched somebody play it, so interest in the game is dwindling during this time period.\n",
    "\n",
    "An example of an upward trend was 'Grand Theft Auto V' (GTA V). The GTA series is very widely known and well established, with GTA V releasing in September of 2013. Since the game has been around for so long and there is not really a competitive scene for it we looked deeper into what was causing this increase below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New game that trails off - Zelda\n",
    "plt.figure(figsize = (15,5))\n",
    "thisDF = df.loc[df['name'] == \"The Legend of Zelda: Breath of the Wild\"]\n",
    "#thisDF = thisDF.loc[thisDF['timestamp']< 1491436800]\n",
    "anotherDF =thisDF\n",
    "\n",
    "x=np.arange(len(anotherDF['viewers'].values))\n",
    "fit = np.polyfit(x ,anotherDF['viewers'].values, deg = 1)\n",
    "\n",
    "plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = \"The Legend of Zelda: Breath of the Wild \")\n",
    "plt.plot(anotherDF['time'], fit[0]*x +fit[1], color = 'red', label='Linear Trend')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"Zelda: Breath of the Wild Viewers over Time\")\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which games rise over time - GTA V\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "thisDF = df.loc[df['name'] == \"Grand Theft Auto V\"]\n",
    "#thisDF = thisDF.loc[thisDF['timestamp']< 1491436800]\n",
    "anotherDF =thisDF\n",
    "\n",
    "x=np.arange(len(anotherDF['viewers'].values))\n",
    "fit = np.polyfit(x ,anotherDF['viewers'].values, deg = 1)\n",
    "\n",
    "plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = \"Grand Theft Auto V\")\n",
    "plt.plot(anotherDF['time'], fit[0]*x +fit[1], color = 'red', label='Linear Trend')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"GTA V - Viewers over Time\")\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some digging we discovered that there were some big streamers that were deviating from their usual games of choice and starting to play GTA V, and when they did so, their followers and fan base continued to watch them. In the graph below, we draw dotted vertical lines for when the streamers 'summit1g', 'lirik' and 'giantwaffle' reach a local peak in their viewership over time (i.e. they start streaming), and we can see that the spikes in viewership correspond almost exactly to the time that these streamers begin playing.\n",
    "\n",
    "To further illustrate the point, we show GTA V's viewership with the viewers from these big streamers substracted. With the exception of the data point around April 13th (which was actually a collection of smaller but still relatively famous streamers), we see again that the spikes are almost entirely caused by the appearance of the big streamers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "thisDF = df.loc[df['name'] == \"Grand Theft Auto V\"]\n",
    "#thisDF = thisDF.loc[thisDF['timestamp']< 1491436800]\n",
    "anotherDF =thisDF\n",
    "\n",
    "summitDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"summit1g\"]\n",
    "summitDF = summitDF.loc[summitDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "lirikDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"lirik\"]\n",
    "lirikDF = lirikDF.loc[lirikDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "giantwaffleDF=dfBig.loc[dfBig[\"ch_channel_name\"]==\"giantwaffle\"]\n",
    "giantwaffleDF = giantwaffleDF.loc[giantwaffleDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "\n",
    "plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = \"Grand Theft Auto V Viewers\")\n",
    "#plt.plot(summitDF['time'],anotherDF['viewers'].values, label = \"Summit Playing GTA\")\n",
    "#plt.plot(lirikDF['time'],lirikDF['viewers'].values, label = \"Lirik Playing GTA\")\n",
    "\n",
    "prev = None\n",
    "for t in lirikDF['time']:\n",
    "    if prev != None:\n",
    "        if (t-prev) > pd.tslib.Timedelta(minutes=240):\n",
    "            plt.axvline(t, color='green', linestyle='--', alpha=0.5, label = \"Lirik Stream\" )\n",
    "    prev = t\n",
    "prev = None\n",
    "for t in summitDF['time']:\n",
    "    if prev != None:\n",
    "        if (t-prev) > pd.tslib.Timedelta(minutes=240):\n",
    "            plt.axvline(t, color='red', linestyle='--', alpha=0.5, label = \"Summit Stream\" )\n",
    "    prev = t\n",
    "prev = None\n",
    "for t in giantwaffleDF['time']:\n",
    "    if prev != None:\n",
    "        if (t-prev) > pd.tslib.Timedelta(minutes=240):\n",
    "            plt.axvline(t, color='black', linestyle='--', alpha=0.5, label = \"Giantwaffle Stream\" )\n",
    "    prev = t\n",
    "    \n",
    "    \n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = OrderedDict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(),bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\"Timing of Big Streamers with GTA V Viewer Spikes\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisDF = df.loc[df['name'] == \"Grand Theft Auto V\"]\n",
    "#thisDF = thisDF.loc[thisDF['timestamp']< 1491436800]\n",
    "anotherDF =thisDF\n",
    "\n",
    "\n",
    "summitDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"summit1g\"]\n",
    "summitDF = summitDF.loc[summitDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "lirikDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"lirik\"]\n",
    "lirikDF = lirikDF.loc[lirikDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "giantwaffleDF=dfBig.loc[dfBig[\"ch_channel_name\"]==\"giantwaffle\"]\n",
    "giantwaffleDF = giantwaffleDF.loc[giantwaffleDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "aiekilluDF=dfBig.loc[dfBig[\"ch_channel_name\"]==\"aiekillu\"]\n",
    "aiekilluDF = aiekilluDF.loc[aiekilluDF[\"stream_game\"]== \"Grand Theft Auto V\"]\n",
    "\n",
    "\n",
    "mainVals =[]\n",
    "summitVals =[]\n",
    "lirikVals = []\n",
    "giantwaffleVals = []\n",
    "aiekilluVals = []\n",
    "\n",
    "anotherDFTimeStamps = anotherDF[\"timestamp\"].values\n",
    "for i in range(0,len(anotherDFTimeStamps)):\n",
    "    thismainVal =  anotherDF.loc[anotherDF[\"timestamp\"]== anotherDFTimeStamps[i]][\"viewers\"].values[0]\n",
    "    thissummitVal =  summitDF.loc[summitDF[\"timestamp\"]== anotherDFTimeStamps[i]][\"viewers\"].values\n",
    "    thislirikVal = lirikDF.loc[lirikDF[\"timestamp\"]== anotherDFTimeStamps[i]][\"viewers\"].values\n",
    "    thisgiantwaffleVal = giantwaffleDF.loc[giantwaffleDF[\"timestamp\"]== anotherDFTimeStamps[i]][\"viewers\"].values\n",
    "    thisaiekilluVal = aiekilluDF.loc[aiekilluDF[\"timestamp\"]== anotherDFTimeStamps[i]][\"viewers\"].values\n",
    "    if(len(thissummitVal)==0):\n",
    "        thissummitVal =0\n",
    "    else:\n",
    "        thissummitVal=thissummitVal[0]\n",
    "    if(len(thislirikVal)==0):\n",
    "        thislirikVal =0\n",
    "    else:\n",
    "        thislirikVal=thislirikVal[0]\n",
    "    if(len(thisgiantwaffleVal)==0):\n",
    "        thisgiantwaffleVal =0\n",
    "    else:\n",
    "        thisgiantwaffleVal=thisgiantwaffleVal[0]\n",
    "    if(len(thisaiekilluVal)==0):\n",
    "        thisaiekilluVal =0\n",
    "    else:\n",
    "        thisaiekilluVal=thisaiekilluVal[0]\n",
    "\n",
    "        \n",
    "    mainVals.append(thismainVal)\n",
    "    summitVals.append(thissummitVal)\n",
    "    lirikVals.append(thislirikVal)\n",
    "    giantwaffleVals.append(thisgiantwaffleVal)\n",
    "    aiekilluVals.append(thisaiekilluVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "\n",
    "plt.plot(anotherDF['time'],anotherDF['viewers'].values, label = \"Grand Theft Auto V Viewers\")\n",
    "plt.plot(anotherDF['time'],np.abs(np.array(mainVals)-np.array(summitVals)-np.array(lirikVals)- np.array(giantwaffleVals)- np.array(aiekilluVals)), label = \"Grand Theft Auto V Viewers without Big Streamer Viewers\")\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = OrderedDict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(),bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\" GTA V - Impact of Big Streamers\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "While it was the case for GTA V that the game's viewership spiked tremendously with the appearance of large streamers, we hypothesized that the converse may also be true for certain popular games, i.e. that people will continue to watch the game even if the big streamers are not streaming it.\n",
    "\n",
    "We considered the game 'PLAYERUNKNOWN'S BATTLEGROUNDS' (PUBG), which recently gained popularity and is actively streamed by both summit1g and lirik and created a similar plot to above. What we saw was that while these 2 do have a considerable impact on the viewership of the game, it is nowhere near the impact size that we saw previously. For GTA V they were raising the numbers from ~5000 to ~60000 (1100% increase), whereas for PUBG the impact size was in the range of 20-50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter example for streamers creating viewership\n",
    "\n",
    "summitDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"summit1g\"]\n",
    "summitDF = summitDF.loc[summitDF[\"stream_game\"]== \"PLAYERUNKNOWN'S BATTLEGROUNDS\"]\n",
    "\n",
    "lirikDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"lirik\"]\n",
    "lirikDF = lirikDF.loc[lirikDF[\"stream_game\"]== \"PLAYERUNKNOWN'S BATTLEGROUNDS\"]\n",
    "\n",
    "thisDF = df.loc[df['name'] == \"PLAYERUNKNOWN'S BATTLEGROUNDS\"]\n",
    "#thisDF = thisDF.loc[thisDF['timestamp']< 1491436800]\n",
    "anotherDF =thisDF\n",
    "\n",
    "\n",
    "mainVals =[]\n",
    "summitVals =[]\n",
    "lirikVals = []\n",
    "\n",
    "anotherDFTimeStamps = anotherDF[\"timestamp\"].values\n",
    "for i in range(0,len(anotherDFTimeStamps)):\n",
    "    thismainVal =  anotherDF.loc[anotherDF[\"timestamp\"]== anotherDFTimeStamps[i]][\"viewers\"].values[0]\n",
    "    thissummitVal =  summitDF.loc[summitDF[\"timestamp\"]== anotherDFTimeStamps[i]][\"viewers\"].values\n",
    "    thislirikVal = lirikDF.loc[lirikDF[\"timestamp\"]== anotherDFTimeStamps[i]][\"viewers\"].values\n",
    "    if(len(thissummitVal)==0):\n",
    "        thissummitVal =0\n",
    "    else:\n",
    "        thissummitVal=thissummitVal[0]\n",
    "    if(len(thislirikVal)==0):\n",
    "        thislirikVal =0\n",
    "    else:\n",
    "        thislirikVal=thislirikVal[0]\n",
    "\n",
    "    mainVals.append(thismainVal)\n",
    "    summitVals.append(thissummitVal)\n",
    "    lirikVals.append(thislirikVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.plot(anotherDF['time'],np.array(mainVals), label = \"PLAYERUNKNOWN'S BATTLEGROUNDS\")\n",
    "plt.plot(anotherDF['time'],np.abs((np.array(mainVals)-np.array(summitVals)-np.array(lirikVals))), label = \"PLAYERUNKNOWN'S BATTLEGROUNDS without Big Streamers\")\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = OrderedDict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(),bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\"PLAYERUNKNOWN'S BATTLEGROUNDS - Impact of Big Streamers\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream viewership by Day of Week and Hour of Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the cyclical nature of overall viewership, we decided to aggregate our data by Day Of Week/Hour Of Day and look at pockets of time that correspond to high viewership through a heatmap.\n",
    "\n",
    "Below we see that for \"PLAYERUNKNOWN'S BATTLEGROUNDS\", the viewership is concentrated in the late evening/late night time periods (in UTC time), meaning that the bulk of the player base is probably in the USA.\n",
    "\n",
    "<img src=\"report-assets/overwatch.png\" width=\"200px;\"/>\n",
    "\n",
    "On the other hand, if we look at the game \"Overwatch\", we had prior knowledge that the game has a big Korean community that streams on twitch. If we look at the heatmap faceted by language (english streams and korean streams), we can see the diffence in the time windows for high viewership. We also see a large hot spot on Saturdays, this was caused by a tournament\\* that occured in Korea during the time we collected the data.\n",
    "\n",
    "*- http://www.gosugamers.net/overwatch/events/632-ogn-overwatch-apex-season-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#are there games that peak at different time periods?\n",
    "heatMapGameList = [\"PLAYERUNKNOWN'S BATTLEGROUNDS\"]\n",
    "\n",
    "thisDF = df.loc[df['name'].isin(heatMapGameList)]\n",
    "#aggregate data by hour of day/day of week\n",
    "thisDF[\"Hour\"] = thisDF[\"time\"].dt.hour\n",
    "thisDF[\"DOW\"] = thisDF[\"time\"].dt.dayofweek\n",
    "\n",
    "f = {'viewers':['mean'], 'name':sole_value, 'DOW': sole_value, 'Hour': sole_value}\n",
    "\n",
    "thisSubGroup= thisDF.groupby(['DOW', 'Hour','name']).agg(f)\n",
    "thisDF = pd.DataFrame(thisSubGroup)\n",
    "thisDF.columns = [\"hour\", \"name\", \"viewersMean\", \"dow\"]\n",
    "neededdf = thisDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i neededdf -w 800 -h 500\n",
    "\n",
    "library(ggplot2)\n",
    "library(viridis)\n",
    "neededdf <- as.data.frame(neededdf)\n",
    "\n",
    "\n",
    "#divide by max scaler\n",
    "#neededdf$viewers= neededdf$viewers/max(neededdf$viewers)\n",
    "ggplot(data = neededdf, aes(x = dow, y = hour)) +\n",
    "  geom_tile(aes(fill = viewersMean/1000)) + \n",
    "  scale_fill_viridis(name = \"Thousands of Viewers (Mean)\") +\n",
    " labs(title=\"PUBG Viewer HeatMap\", x= \"Day Of Week (Monday-0 to Sunday-6)\", y = \"Hour Of Day 0-24\") +\n",
    "  theme(plot.title = element_text(hjust = 0.5))+ \n",
    " facet_wrap(~name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#are there games that peak at different time periods? show heatmap faceted by language\n",
    "sole_value = lambda x : list(x)[0]\n",
    "\n",
    "thisDF = dfBig[dfBig['stream_game'] == \"Overwatch\"]\n",
    "\n",
    "#aggregate data by hour of day/day of week\n",
    "thisDF[\"Hour\"] = thisDF[\"time\"].dt.hour\n",
    "thisDF[\"DOW\"] = thisDF[\"time\"].dt.dayofweek\n",
    "\n",
    "f = {'viewers':['sum','count', 'mean'], 'ch_broadcaster_language':sole_value, 'DOW': sole_value, 'Hour': sole_value}\n",
    "\n",
    "thisSubGroup= thisDF.groupby(['stream_game','DOW', 'Hour','ch_broadcaster_language']).agg(f)\n",
    "thisDF = pd.DataFrame(thisSubGroup)\n",
    "\n",
    "\n",
    "#thisDF.loc[thisDF[\"ch_broadcaster_language\"]==\"ko\"]]\n",
    "neededdf = thisDF.loc[thisDF[\"ch_broadcaster_language\"][\"<lambda>\"]==\"ko\"]\n",
    "neededdf= neededdf.append(thisDF.loc[thisDF[\"ch_broadcaster_language\"][\"<lambda>\"]==\"en\"])\n",
    "neededdf.columns = [\"hour\", \"language\", \"dow\", \"viewersSum\", \"viewersCount\", \"viewersMean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i neededdf -w 800 -h 500\n",
    "\n",
    "library(ggplot2)\n",
    "library(viridis)\n",
    "neededdf <- as.data.frame(neededdf)\n",
    "head(neededdf)\n",
    "\n",
    "#divide by max scaler\n",
    "#neededdf$viewers= neededdf$viewers/max(neededdf$viewers)\n",
    "\n",
    "ggplot(data = neededdf, aes(x = dow, y = hour)) +\n",
    "  geom_tile(aes(fill = viewersMean)) + \n",
    "  scale_fill_viridis(name = \"Viewers (Mean)\") +\n",
    "labs(title=\"Overwatch Viewers (per stream)\", x= \"Day Of Week (Monday-0 to Sunday-6)\", y = \"Hour Of Day 0-24\") +\n",
    "  theme(plot.title = element_text(hjust = 0.5))+ facet_wrap(~language)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better illustrate how viewership varies over time in various time zones around the world, we used D3 to create the below visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analyzing stream viewership by time of day - globally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "While analyzing viewership for different streams, we looked at when certain game streams achieve their 'peaks'. We found some interesting insights by looking at this data, and overlaying it with the time of day around the world. Twitch is used worldwide and games are streamed from across the world. Below, we analyze two games showing different patterns.\n",
    "\n",
    "- FIFA 17\n",
    "\n",
    "- Dota 2\n",
    "\n",
    "Since viewership varies across the world, we decided to make an interactive graph to visualize this using D3js and C3js libraries.\n",
    "\n",
    "Relevant Credits:\n",
    "\n",
    " - http://bl.ocks.org/mbostock/4597134\n",
    " - https://gist.github.com/johan/4645501\n",
    " - http://c3js.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"height:300px;\" src=\"report-assets/fifa-17.png\"/>\n",
    "\n",
    "#### FIFA 17 \n",
    "\n",
    "FIFA 17 is a soccer game, and soccer as a sport and a video game is more popular across Europe. What we find is that FIFA 17 streams reach peak viewership during late-evenings and night time in Europe. This could be due to the fact that people are coming home from work/college to play FIFA. \n",
    "\n",
    "##### INTERACTIVE VISUALIZATION:\n",
    "*Note: Hover over the timeseries graph below to see the daylight overlay move across the world-map. The dark-gray region shows the part of the world that has night time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<style>\n",
    "    #frame { width: 1000px; height:800px; border: 1px solid black; }\n",
    "    #frame {\n",
    "        -ms-zoom: 0.95;\n",
    "        -moz-transform: scale(0.95);\n",
    "        -moz-transform-origin: 0 0;\n",
    "        -o-transform: scale(0.95);\n",
    "        -o-transform-origin: 0 0;\n",
    "        -webkit-transform: scale(0.95);\n",
    "        -webkit-transform-origin: 0 0;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div id=\"wrap\">\n",
    "<iframe id=\"frame\" src=\"https://cyruslala.github.io/EDAV_Columbia2017_Twitch/d3/fifaindex.html\"></iframe>\n",
    "</div>\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"report-assets/dota.png\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Dota 2:\n",
    "\n",
    "Dota 2 is a popular 'moba' played across the world. There are concentrated player bases in the US, Europe and Asia. \n",
    "\n",
    "Again, this is visible clearly in the Daylight map overlay below.\n",
    "\n",
    "##### INTERACTIVE VISUALIZATION:\n",
    "\n",
    "*Note: Hover over the timeseries graph below to see the daylight overlay move across the world-map. The dark-gray region shows the part of the world that has night time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''<style>\n",
    "    #frame { width: 1000px; height:800px; border: 1px solid black; }\n",
    "    #frame {\n",
    "        -ms-zoom: 0.95;\n",
    "        -moz-transform: scale(0.95);\n",
    "        -moz-transform-origin: 0 0;\n",
    "        -o-transform: scale(0.95);\n",
    "        -o-transform-origin: 0 0;\n",
    "        -webkit-transform: scale(0.95);\n",
    "        -webkit-transform-origin: 0 0;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div id=\"wrap\">\n",
    "<iframe id=\"frame\" src=\"https://cyruslala.github.io/EDAV_Columbia2017_Twitch/d3/dotaindex.html\"></iframe>\n",
    "</div>\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from some outliers, we noticed that there are multiple peaks in viewership per-day for Dota. These seem to occur during night time in US and Europe. This can be observed as a plateau of peak viewership as night progresses in Europe and Asia.\n",
    "\n",
    "However there is clearly a huge spike in viewership for Dota 2 from  *1st April to 4th April*. Additionally, the peaks for these times occur when it is day time in China. \n",
    "\n",
    "<img src=\"report-assets/dota-tournament.png\" width=\"600px\"/>\n",
    "\n",
    "Digging deeper, we found that there was a Dota 2 tournament held in China during these days. The finals of the tournament was on the *4th of April*. This is another graph that emphasises how viewership on Twitch skyrockets during large eSports tournaments. \n",
    "\n",
    "Read more about the tournament <a href=\"http://www.dota2.com.cn/dac/english/match?date=04-01\">here.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How quickly do channels reach 'peak' viewership?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at how well the peaks of big streamers corresponded to peaks of viewership in our GTA V analysis, we wanted to explore the question of how quickly the big streamers reach their peaks from the time they start streaming.\n",
    "\n",
    "When a streamer goes online, all of their followers recieve a notification via email informing them that the streamer has gone live. Below, we once again look at the time series data for lirik and summit1g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how quickly do big streamers reach their peaks when they start streaming?\n",
    "\n",
    "lirikTimeDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"lirik\"][50:313]\n",
    "summitTimeDF = dfBig.loc[dfBig[\"ch_channel_name\"]==\"summit1g\"][200:730]\n",
    "\n",
    "lirikTimeDF = lirikTimeDF.set_index(\"time\")\n",
    "lirikTimeDF = lirikTimeDF.resample(\"10 min\")\n",
    "lirikTimeDF= lirikTimeDF.mean()\n",
    "lirikTimeDF['viewers'] = lirikTimeDF['viewers'].fillna(0)\n",
    "lirikTimeDF= lirikTimeDF.iloc[50:].iloc[:-5]\n",
    "\n",
    "summitTimeDF = summitTimeDF.set_index(\"time\")\n",
    "summitTimeDF = summitTimeDF.resample(\"10 min\")\n",
    "summitTimeDF= summitTimeDF.mean()\n",
    "summitTimeDF['viewers'] = summitTimeDF['viewers'].fillna(0)\n",
    "summitTimeDF= summitTimeDF.iloc[50:].iloc[:-50]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For lirik we see that typically he very quickly reaches a large amount of viewers (10 or 20 minutes), and then somtimes builds up over time. Looking a bit deeper, we found that the secondary spikes usually corresponded to him switching to more popular games and quickly gaining more viewers in that way.\n",
    "\n",
    "The data point around 2nd april was actually him participating in a talk show with a scheduled start time, which could explain the immediate reaching of the peak.\n",
    "\n",
    "Below we zoom in on his first stream in this data to illustrate the quick rise once he starts (basically reaches the peak within 20 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(list(lirikTimeDF.index),lirikTimeDF['viewers'].values, label = \"lirik Viewers\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\"Viewers for the channel: 'lirik'\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopeDF = lirikTimeDF[200:300]\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(list(slopeDF.index),slopeDF['viewers'].values, label = \"lirik Viewers\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\"Viewers for the channel: 'lirik' (Zoomed in)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "myFmt = mdates.DateFormatter('%m-%d %H:00')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For summit1g we see slightly slower rises, but we also see wider ranges of activity, showing that his streams are slightly longer.\n",
    "\n",
    "One possible explanation is also that summit is attracting new viewers recently that are not part of his previous follower base and they trickle in slower as he continues to stream.\n",
    "\n",
    "Once again, we zoom in on the first period of activity to better illustrate the timing window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(list(summitTimeDF.index),summitTimeDF['viewers'].values, label = \"summit1g Viewers\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\"Viewers for the channel: 'summit1g'\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopeDF = summitTimeDF[150:300]\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(list(slopeDF.index),slopeDF['viewers'].values, label = \"summit1g Viewers\")\n",
    "myFmt = mdates.DateFormatter('%m-%d %H:00')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "labels = plt.gca().get_xticklabels()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.setp(labels, rotation=30)\n",
    "plt.title(\"Viewers for the channel: 'summit1g' (Zoomed in)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does FPS (Frames Per Second) and Video Resolution Affect Viewership?\n",
    "\n",
    "We observe that the majority of streamer's FPS is either 30 or 60. High frame rate does not correspond to high viewership, but streamers with high viewership have between the standard 30 and 60 fps.\n",
    "\n",
    "We observe a similar pattern for video resolution, with concentrations around 720 and 1080. Once again, high resolution does not necessarily correspond to high viewership, but streamers with high viewership generally have good screen resolution between 720 and 1080."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How does FPS affect viewership\n",
    "sole_value = lambda x : list(x)[0]\n",
    "\n",
    "thisDF = dfBig\n",
    "\n",
    "#aggregate data by hour of day/day of week\n",
    "thisDF[\"Hour\"] = thisDF[\"time\"].dt.hour\n",
    "thisDF[\"DOW\"] = thisDF[\"time\"].dt.dayofweek\n",
    "\n",
    "f = {'viewers':['median','count'],'stream_game':sole_value, 'ch_channel_name':sole_value, 'average_fps':'mean', 'video_height':'mean'}\n",
    "\n",
    "thisSubGroup= thisDF.groupby(['stream_game','ch_channel_name']).agg(f)\n",
    "thisDF = pd.DataFrame(thisSubGroup)\n",
    "#neededdf[\"DOW\"] = neededdf.index[:][0]\n",
    "#neededdf[\"Hour\"] = \n",
    "#neededdf[\"ch_language\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thisDF['viewers'].values[:,0]\n",
    "thisDF = thisDF.loc[thisDF['average_fps']['mean'].values<200]\n",
    "#thisDF['average_fps']['mean']\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.scatter(thisDF['average_fps'].values,thisDF['viewers'].values[:,0],s =2,c='purple')\n",
    "plt.axvline(30, color='green', linestyle='--', alpha=0.6, label = '30 fps')\n",
    "plt.axvline(60, color='blue', linestyle='--', alpha=0.6, label = '60 fps')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"Viewers by Average FPS\")\n",
    "plt.xlabel(\"FPS\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thisDF['viewers'].values[:,0]\n",
    "#thisDF = thisDF.loc[thisDF['video_height']['mean'].values<200]\n",
    "#thisDF['average_fps']['mean']\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.scatter(thisDF['video_height'].values,thisDF['viewers'].values[:,0],s =2,c='purple')\n",
    "plt.axvline(720, color='green', linestyle='--', alpha=0.6, label = '720p')\n",
    "plt.axvline(1080, color='blue', linestyle='--', alpha=0.6, label = '1080p')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"Viewers by Video Height\")\n",
    "plt.xlabel(\"Video Height\")\n",
    "plt.ylabel(\"Viewers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "The analysis of data from Twitch revealed a lot of insights regarding viewership. However, the limitations, future directions and lessons learnt are listed below:\n",
    "\n",
    "* **Limitations**\n",
    "\n",
    "    - One of the major limitations of our analysis is the missing unique viewer information per 10-minute time interval. We had to aggregate data every hour by taking the mean viewership in that hour, which is not very accurate.\n",
    "\n",
    "    - We have no information about the age/demographics of the viewers.\n",
    "\n",
    "\n",
    "* **Future Directions**\n",
    "\n",
    "    - This data could be used by either game designers or streamers. They could use the insights to uncover what drives interest in games.\n",
    "\n",
    "    - This analysis can be repeated for other video based/ view-based social networks or platforms.\n",
    "\n",
    "\n",
    "* **Lessons Learnt**\n",
    "\n",
    "    - We learnt how to setup machines on Amazon AWS - EC2 & RDS to fetch/save data.\n",
    "    - We learnt how to interoperate between Python and R.\n",
    "    - We learnt how to deal with large files (~2GB) in Python and R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to run the code:\n",
    "\n",
    "- Required: Python 2.7, Latest version of R (RStudio).\n",
    "\n",
    "- Dependencies: Numpy, Pandas, rpy2, matplotlib, scipy \n",
    "\n",
    "- Data: Hosted on Google Drive (https://drive.google.com/drive/folders/0B_1PeBrwSWY1bUZLU3laSldEaWc?usp=sharing)\n",
    "\n",
    "*Note:* Data is available to anyone with LionMail access.\n",
    "\n",
    "- Data Fetch/Cleanup code: \n",
    "    * https://github.com/shashankrao/TwitchDataAnalysis/blob/master/notebooks-code/Giantbomb_Pull.ipynb\n",
    "    * https://github.com/shashankrao/TwitchDataAnalysis/blob/master/notebooks-code/Giantbomb_Cleanup.ipynb\n",
    "    * https://github.com/shashankrao/TwitchDataAnalysis/blob/master/notebooks-code/TwitchScraper.py\n",
    "    \n",
    "    \n",
    "- Repository with everything: https://github.com/shashankrao/TwitchDataAnalysis"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
